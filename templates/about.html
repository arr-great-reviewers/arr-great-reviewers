{% extends "base.html" %}

{% block title %}About - ARR Great Reviewers{% endblock %}

{% block description %}Learn about ARR Great Reviewers - our motivation to recognize outstanding peer reviewers, data collection methodology, and ranking system for ACL Rolling Review.{% endblock %}

{% block keywords %}about, motivation, methodology, data collection, ranking algorithm, ACL Rolling Review, peer review evaluation, academic review metrics, transparency, research methodology{% endblock %}

{% block og_title %}About - ARR Great Reviewers{% endblock %}
{% block og_description %}Learn about ARR Great Reviewers - our motivation to recognize outstanding peer reviewers, data collection methodology, and ranking system for ACL Rolling Review.{% endblock %}
{% block og_type %}article{% endblock %}

{% block twitter_title %}About - ARR Great Reviewers{% endblock %}
{% block twitter_description %}Learn about ARR Great Reviewers - our motivation to recognize outstanding peer reviewers, data collection methodology, and ranking system for ACL Rolling Review.{% endblock %}

{% block schema_type %}Article{% endblock %}
{% block schema_name %}About - ARR Great Reviewers{% endblock %}
{% block schema_description %}Learn about ARR Great Reviewers - our motivation to recognize outstanding peer reviewers, data collection methodology, and ranking system for ACL Rolling Review.{% endblock %}
{% block schema_additional %},
    "articleSection": "About",
    "author": {
      "@type": "Organization",
      "name": "ARR Great Reviewers"
    },
    "about": ["Motivation", "Data Collection", "Ranking Algorithm", "Peer Review Recognition", "Academic Methodology"]{% endblock %}

{% block content %}
<div class="content-section">
  <h2>About ARR Great Reviewers</h2>
  <div class="about-content">
    
    <h3>Our Motivation</h3>
    <p>Most reviews get written, submitted, and forgotten. But across all ARR cycles where Area Chairs have awarded "Great Review" recognitions, thousands of reviews were so helpful that they received this distinction. Yet these recognitions get buried at the bottom of stats pages, and the amazing reviewers behind them remain invisible.</p>
    
    <p>You know how Area Chairs can mark "Great Reviews"? These recognitions are tracked in ARR's public statistics, but the outstanding reviewers who consistently deliver exceptional reviews rarely get the credit they deserve. That's why we built <strong>ARR Great Reviewers</strong> - to finally give credit where it's due.</p>
    
    {% include "great_review_banner.html" %}
    
    <p>Great reviews can transform a paper - they clarify murky ideas, identify crucial gaps, and push our field forward. Yet reviewers rarely get thanked for this essential work. This project is a way of saying what authors often think but rarely say: <strong>thank you</strong> to the reviewers who make our research better.</p>
    
    <p>The entire analysis is transparent and open-source, with code available at <a href="https://github.com/arr-great-reviewers/arr-great-reviewers">GitHub</a>, covering all ARR cycles where "Great Review" data is available.</p>
    
    <h3>Methodology</h3>
    <p>This section explains the data collection and processing for ARR great reviewers.</p>
    
    <h4>Data Collection</h4>
    <p>The dataset comes from the ACL Rolling Review public statistics endpoints. We fetch JSON files for each iteration listed in <code>config/data_sources.toml</code>. Each entry includes reviewer name, institution, counts of reviews and recognized reviews, and the percentage of recognized reviews.</p>
    
    <p>Downloaded files are validated against a reference schema and stored under <code>data/raw/</code>. We then concatenate these files and clean numeric fields to build a unified DataFrame. Aggregations produce metrics for top reviewers and institutions which are exported as JSON under <code>data/metrics/</code>. These metrics feed the static site visualisations.</p>
    
    <h4>Ranking and Tie-Breaking</h4>
    <p>When ranking reviewers and institutions, ties are resolved using the following hierarchy:</p>
    
    <h5>For Recognition Count Rankings:</h5>
    <ol>
      <li><strong>Primary</strong>: Total number of recognized reviews (descending)</li>
      <li><strong>Tie-breaker 1</strong>: Recognition rate (recognized/total reviews) (descending)</li>
      <li><strong>Tie-breaker 2</strong>: Total number of reviews (descending)</li>
    </ol>
    
    <h5>For Recognition Rate Rankings:</h5>
    <ol>
      <li><strong>Primary</strong>: Recognition percentage (descending)</li>
      <li><strong>Tie-breaker 1</strong>: Total number of recognized reviews (descending)</li>
      <li><strong>Tie-breaker 2</strong>: Total number of reviews (descending)</li>
    </ol>
    
    <p>This ensures consistent and fair rankings where reviewers with identical primary metrics are ordered by meaningful secondary criteria that reflect their overall contribution and review volume.</p>
    
    <h4>Data Quality</h4>
    <p>We match reviewers across cycles using their OpenReview IDs to handle name changes and typos. When someone changes institutions, we use their current affiliation but count all their past reviews.</p>
    
    <p>We only rank reviewers with at least 5 total reviews and institutions with at least 3 reviewers. This reduces noise from small samples.</p>
    
    
    <h4>What This Doesn't Capture</h4>
    <ul>
      <li>Review quality beyond ARR's "recognition" metric</li>
      <li>Reviewers who don't use ARR</li>
      <li>Historical institutional affiliations (we use current ones)</li>
      <li>Differences between research areas or reviewer experience levels</li>
    </ul>
    
    <h4>Privacy</h4>
    <p>All data comes from public ARR statistics. Reviewers can ask ARR organizers to opt out of future rankings.</p>
    
    <h4>Limitations</h4>
    <p>ARR defines "recognized" reviews internally - we don't control this criteria. Our data only goes back to April 2024 and only covers ARR participants.</p>
    
    <p>Recognition doesn't equal review quality. A helpful review might not be "recognized" and vice versa.</p>
    
    <h4>Reproducibility</h4>
    <p>Raw data files and processing code are available on <a href="https://github.com/arr-great-reviewers/arr-great-reviewers">GitHub</a>. Data schemas are validated on download, and the entire analysis pipeline is open-source and reproducible.</p>
  </div>
</div>

<style>
.about-content {
  font-size: 1.1rem;
  line-height: 1.8;
}

.about-content h3 {
  margin-top: 2.5rem;
  margin-bottom: 1.5rem;
  color: var(--primary-color);
  font-size: 1.5rem;
  font-weight: 600;
  border-bottom: 2px solid var(--border-color);
  padding-bottom: 0.5rem;
}

.about-content h4 {
  margin-top: 2rem;
  margin-bottom: 1rem;
  color: var(--text-primary);
  font-size: 1.25rem;
  font-weight: 600;
}

.about-content h5 {
  margin-top: 1.5rem;
  margin-bottom: 0.75rem;
  color: var(--text-primary);
  font-size: 1.125rem;
  font-weight: 600;
}

.about-content p {
  margin-bottom: 1.5rem;
  color: var(--text-primary);
}

.about-content ol, .about-content ul {
  margin-left: 2rem;
  margin-bottom: 1.5rem;
}

.about-content li {
  margin-bottom: 0.5rem;
  color: var(--text-primary);
}

.about-content code {
  background-color: var(--bg-tertiary);
  padding: 0.2rem 0.4rem;
  border-radius: 0.25rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  font-size: 0.9em;
  color: var(--text-primary);
}

.about-content strong {
  color: var(--primary-color);
  font-weight: 600;
}

.about-content a {
  color: var(--primary-color);
  text-decoration: none;
}

.about-content a:hover {
  text-decoration: underline;
}
</style>
{% endblock %}