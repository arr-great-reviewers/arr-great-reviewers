{% extends "base.html" %}

{% block title %}Methodology - ARR Great Reviewers{% endblock %}

{% block description %}Learn about the data collection, processing, and ranking methodology used to identify outstanding peer reviewers in ACL Rolling Review. Comprehensive documentation of our transparent evaluation process.{% endblock %}

{% block keywords %}methodology, data collection, ranking algorithm, ACL Rolling Review, peer review evaluation, academic review metrics, transparency, research methodology{% endblock %}

{% block og_title %}Methodology - ARR Great Reviewers{% endblock %}
{% block og_description %}Learn about the data collection, processing, and ranking methodology used to identify outstanding peer reviewers in ACL Rolling Review. Comprehensive documentation of our transparent evaluation process.{% endblock %}
{% block og_type %}article{% endblock %}

{% block twitter_title %}Methodology - ARR Great Reviewers{% endblock %}
{% block twitter_description %}Learn about the data collection, processing, and ranking methodology used to identify outstanding peer reviewers in ACL Rolling Review. Comprehensive documentation of our transparent evaluation process.{% endblock %}

{% block schema_type %}Article{% endblock %}
{% block schema_name %}Methodology - ARR Great Reviewers{% endblock %}
{% block schema_description %}Learn about the data collection, processing, and ranking methodology used to identify outstanding peer reviewers in ACL Rolling Review. Comprehensive documentation of our transparent evaluation process.{% endblock %}
{% block schema_additional %},
    "articleSection": "Methodology",
    "author": {
      "@type": "Organization",
      "name": "ARR Great Reviewers"
    },
    "about": ["Data Collection", "Ranking Algorithm", "Peer Review Evaluation", "Academic Methodology"]{% endblock %}

{% block content %}
<div class="content-section">
  <h2>Methodology</h2>
  <div class="methodology-content">
    <p>This document explains the data collection and processing for ARR great reviewers.</p>
    
    <h3>Data Collection</h3>
    <p>The dataset comes from the ACL Rolling Review public statistics endpoints. We fetch JSON files for each iteration listed in <code>config/data_sources.toml</code>. Each entry includes reviewer name, institution, counts of reviews and recognized reviews, and the percentage of recognized reviews.</p>
    
    <p>Downloaded files are validated against a reference schema and stored under <code>data/raw/</code>. We then concatenate these files and clean numeric fields to build a unified DataFrame. Aggregations produce metrics for top reviewers and institutions which are exported as JSON under <code>data/metrics/</code>. These metrics feed the static site visualisations.</p>
    
    <h3>Ranking and Tie-Breaking</h3>
    <p>When ranking reviewers and institutions, ties are resolved using the following hierarchy:</p>
    
    <h4>For Recognition Count Rankings:</h4>
    <ol>
      <li><strong>Primary</strong>: Total number of recognized reviews (descending)</li>
      <li><strong>Tie-breaker 1</strong>: Recognition rate (recognized/total reviews) (descending)</li>
      <li><strong>Tie-breaker 2</strong>: Total number of reviews (descending)</li>
    </ol>
    
    <h4>For Recognition Rate Rankings:</h4>
    <ol>
      <li><strong>Primary</strong>: Recognition percentage (descending)</li>
      <li><strong>Tie-breaker 1</strong>: Total number of recognized reviews (descending)</li>
      <li><strong>Tie-breaker 2</strong>: Total number of reviews (descending)</li>
    </ol>
    
    <p>This ensures consistent and fair rankings where reviewers with identical primary metrics are ordered by meaningful secondary criteria that reflect their overall contribution and review volume.</p>
    
    <h3>Limitations</h3>
    <p>Limitations include potential inconsistencies in institution names and the fact that recognition percentages can be influenced by small sample sizes. More details can be found in the project README.</p>
  </div>
</div>

<style>
.methodology-content {
  font-size: 1.1rem;
  line-height: 1.8;
}

.methodology-content h3 {
  margin-top: 2.5rem;
  margin-bottom: 1.5rem;
  color: var(--primary-color);
  font-size: 1.5rem;
  font-weight: 600;
  border-bottom: 2px solid var(--border-color);
  padding-bottom: 0.5rem;
}

.methodology-content h4 {
  margin-top: 2rem;
  margin-bottom: 1rem;
  color: var(--text-primary);
  font-size: 1.25rem;
  font-weight: 600;
}

.methodology-content p {
  margin-bottom: 1.5rem;
  color: var(--text-primary);
}

.methodology-content ol {
  margin-left: 2rem;
  margin-bottom: 1.5rem;
}

.methodology-content li {
  margin-bottom: 0.5rem;
  color: var(--text-primary);
}

.methodology-content code {
  background-color: var(--bg-tertiary);
  padding: 0.2rem 0.4rem;
  border-radius: 0.25rem;
  font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
  font-size: 0.9em;
  color: var(--text-primary);
}

.methodology-content strong {
  color: var(--primary-color);
  font-weight: 600;
}
</style>
{% endblock %}
